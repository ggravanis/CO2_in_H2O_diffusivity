{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T13:42:40.289777Z",
     "start_time": "2025-01-10T13:42:40.260540Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "\n",
    "## Add this line for reproducibility reasons (to have the same random seed in all keras layers)\n",
    "tf.keras.utils.set_random_seed(100)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:42:42.031856Z",
     "start_time": "2025-01-10T13:42:42.010600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_loss(history, title,save_params):\n",
    "    \"\"\"\n",
    "    Visualize the training procedure (Identify any case of over or under fitting)\n",
    "    :param history: history of the training procedure\n",
    "    :param title: title of the image produced \n",
    "    \"\"\"\n",
    "    \n",
    "    # todo: add a flag for saving or not the figure\n",
    "    \n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    if save_params['save_figure']:\n",
    "        plt.savefig(save_params['path']+'loss.png')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ],
   "id": "ac53ad01a4a2e791",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:42:43.735989Z",
     "start_time": "2025-01-10T13:42:43.719974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_reconstruction(test, pred,save_params):\n",
    "    \"\"\"\n",
    "    Evaluate the reconstruction values of the test set.\n",
    "    Creates scatter plots with the true and the predicted values of the autoencoder. \n",
    "    :param test: test set of the data\n",
    "    :param pred: predictions of the test set\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    ax[0].scatter(test['T'], pred[:, 0])\n",
    "    ax[0].set_title('Temperature')\n",
    "    ax[0].set_xlabel('True values')\n",
    "    ax[0].set_ylabel('Reconstructed values')\n",
    "    #######################\n",
    "    ax[1].scatter(test['P'], pred[:, 1])\n",
    "    ax[1].set_title('Pressure')\n",
    "    ax[1].set_xlabel('True values')\n",
    "    ax[1].set_ylabel('Reconstructed values')\n",
    "    ###########\n",
    "    ax[2].scatter(test['D'], pred[:, 2])\n",
    "    ax[2].set_title('Diffusivity')\n",
    "    ax[2].set_xlabel('True values')\n",
    "    ax[2].set_ylabel('Reconstructed values')\n",
    "    if save_params['save_figure']:\n",
    "        plt.savefig(save_params['path']+'reconstruction.png')\n",
    "    plt.show()\n",
    "    # fig.clf()"
   ],
   "id": "7012ce5b822a54c6",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:42:47.171831Z",
     "start_time": "2025-01-10T13:42:47.167091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def error(dfin, dfout):\n",
    "    \"\"\"\n",
    "    Calculate the error between the predicted and actual\n",
    "    \"\"\"\n",
    "    t_error = (dfin[:, 0] - dfout[:, 0]) ** 2\n",
    "    p_error = (dfin[:, 1] - dfout[:, 1]) ** 2\n",
    "    d_error= (dfin[:, 2] - dfout[:, 2]) ** 2\n",
    "    error_all = t_error + p_error + d_error\n",
    "    error_df = pd.DataFrame([t_error, p_error, d_error, error_all]).transpose()\n",
    "    \n",
    "    return error_df"
   ],
   "id": "e75db658aaa38b70",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:42:49.184669Z",
     "start_time": "2025-01-10T13:42:49.167096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_sensitivity(_df_results, name, _save_params):\n",
    "    \"\"\"\n",
    "    Creates a 3D plot with all Diffusivity values over temperature and pressure. The experimental results are also displayed in this plot. \n",
    "    \n",
    "    \"\"\"    \n",
    "    _md = pd.read_csv('../data/CO2_clean.csv', usecols=['Index', 'T', 'P', 'D'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    ax.scatter(_df_results['T'], _df_results['P'], _df_results['D'],alpha=0.2)\n",
    "    ax.scatter(_md['T'], _md['P'], _md['D'],alpha=0.5, s=80, marker='^')\n",
    "    ax.legend(['Predictions', 'MD'], loc='upper left')\n",
    "    \n",
    "    ax.set_xlabel('Temperature\\n(K)')\n",
    "    ax.set_ylabel('Pressure\\n(MPa)')\n",
    "    ax.set_zlabel('Diffusivity\\n($10^{-9} m^2/s$)')\n",
    "    \n",
    "    if _save_params['save_figure']:\n",
    "        plt.savefig(_save_params['save_path'] + '/{}_sensitivity.png'.format(name))\n",
    "    plt.show()"
   ],
   "id": "3de95559083e07c0",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:42:51.912434Z",
     "start_time": "2025-01-10T13:42:51.886123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def export_results_autoencoder(_model, _scaler):\n",
    "    \"\"\"\n",
    "    Exports the trained autoencoder \n",
    "    \"\"\"\n",
    "\n",
    "    diffusivities = np.arange(0, 25, 25 / 1000)  # create a vector with small step to locate the minimum error\n",
    "\n",
    "    _results_df = pd.DataFrame()\n",
    "    for i in range(275, 625, 10):\n",
    "        temperatures = [i for d in range(len(diffusivities))]\n",
    "        for j in range(1, 1000, 10):\n",
    "            Pressure = j / 10\n",
    "\n",
    "            pressures = [Pressure for i in range(len(temperatures))]\n",
    "            temp_max = 625\n",
    "            # temp_max = 369.9 * Pressure ** (0.089)\n",
    "            temp = {'T': temperatures, 'P': pressures, 'D': diffusivities}\n",
    "            _df_for_test = pd.DataFrame(temp)\n",
    "            _df_for_test = _df_for_test[_df_for_test['T'] < temp_max]\n",
    "            try:\n",
    "                _temp_df_scaled = _scaler.transform(_df_for_test)\n",
    "                _results = _model.predict(_temp_df_scaled)\n",
    "                # use the error function to get the error values for all T and P pairs\n",
    "                _error_df = error(_temp_df_scaled, _results)\n",
    "                # find the diffusivity value for the specific P and T with minimum error\n",
    "                _min_error = _error_df[[3]].idxmin()\n",
    "                _best_value = _df_for_test.iloc[_min_error]\n",
    "                _results_df = pd.concat([_results_df, _best_value], ignore_index=True)\n",
    "\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "    return _results_df"
   ],
   "id": "a59d353262be7a0b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T13:43:00.135759Z",
     "start_time": "2025-01-10T13:43:00.119987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_boxplot(_df,_save_params):\n",
    "    plt.boxplot(_df[0])\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Autoencoder MSE')\n",
    "    plt.xticks([1],['{} runs'.format(len(_df[0]))])\n",
    "    if _save_params['save_figure']:\n",
    "        plt.savefig(_save_params['path'] + 'boxplot_Autoencoder.png', dpi=300) \n",
    "    plt.show()"
   ],
   "id": "25407ec9ff265a8f",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-10T14:02:26.579502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    %matplotlib notebook\n",
    "    save_params ={'path': '../results/',\n",
    "                  'save_figure' : False}\n",
    "    \n",
    "    # load the data\n",
    "    df = pd.read_csv('../data/CO2_clean.csv', usecols=['Index', 'T', 'P', 'D'])\n",
    "    X = df[['T', 'P', 'D']]\n",
    "    y = df['D']\n",
    "\n",
    "    # Define dataframes \n",
    "    results_auto = {}\n",
    "    predictions_auto = pd.DataFrame()\n",
    "    \n",
    "    ###########################\n",
    "    ####### AUTOENCODER #######\n",
    "    ###########################\n",
    "    \n",
    "    ## Set callbacks ##\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "    reduce_lron_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    ##  Define the Architecture ##\n",
    "    input_layer = keras.Input(shape=(3,), name='input_layer')\n",
    "    encoder_layer_1 = layers.Dense(44, activation='elu', name='encoder_layer_1')(input_layer)\n",
    "    encoder_layer_2 = layers.Dense(72, activation='elu', name='encoder_layer_2')(encoder_layer_1)\n",
    "    latent = layers.Dense(2, activation='elu', name='latent_space')(encoder_layer_2)\n",
    "    decoder_layer_1 = layers.Dense(72, activation='elu', name='decoder_layer_1')(latent)\n",
    "    decoder_layer_2 = layers.Dense(44, activation='elu', name='decoder_layer_2')(decoder_layer_1)\n",
    "    output_layer = layers.Dense(3, activation='elu', name='output_layer')(decoder_layer_2)\n",
    "\n",
    "\n",
    "    for seed in range(100):\n",
    "        \n",
    "        ## Clear keras session before each train\n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "        ## Split and scale the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=seed)         \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        ## Create and train the AUTOENCODER ##\n",
    "        autoencoder = keras.Model(input_layer, output_layer)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        history = autoencoder.fit(X_train_scaled, X_train_scaled,\n",
    "                                  verbose=0,\n",
    "                                  epochs=1000,\n",
    "                                  batch_size=32,\n",
    "                                  shuffle=False,\n",
    "                                  validation_data=(X_train_scaled, X_train_scaled),\n",
    "                                  callbacks=[reduce_lron_plateau, early_stopping])\n",
    "\n",
    "        # Check training progress for some seeds\n",
    "        if seed in [0,50,99]:\n",
    "            # visualize loss #\n",
    "            visualize_loss(history, 'Autoencoder loss',save_params)\n",
    "            # Check reconstruction #\n",
    "            autoencoder_reconstruction = autoencoder.predict(X_test_scaled)\n",
    "            autoencoder_reconstruction = scaler.inverse_transform(autoencoder_reconstruction)\n",
    "            evaluate_reconstruction(X_test, autoencoder_reconstruction,save_params)\n",
    "\n",
    "        ## Find the D's using the Autoencoder ## \n",
    "        diffusivity_values = np.arange(0, 25, 25 / 1000)  # create a vector with small step to locate the minimum error\n",
    "        autoencoder_test = pd.DataFrame()\n",
    "        \n",
    "        for index, row in X_test.iterrows():\n",
    "            \n",
    "            ## Create Pressure and Temperature vectors for each D\n",
    "            pressures = [row['P'] for pressure in range(len(diffusivity_values))]\n",
    "            temperatures = [row['T'] for temperature in range(len(diffusivity_values))]\n",
    "            \n",
    "            ## Create and scale a Dataframe from the P, T and D vectors \n",
    "            generated_df = pd.DataFrame.from_dict({'T': temperatures, 'P': pressures, 'D': diffusivity_values})\n",
    "            temp_df_scaled = scaler.transform(generated_df)\n",
    "            \n",
    "            # get the autoencoder predictions\n",
    "            results = autoencoder.predict(temp_df_scaled)\n",
    "            # use the error function to get the error values for all T and P pairs\n",
    "            error_df = error(temp_df_scaled, results)\n",
    "            # find the diffusivity value for the specific P and T with minimum error\n",
    "            min_error = error_df[[3]].idxmin()\n",
    "            best_value = generated_df.iloc[min_error]\n",
    "            autoencoder_test = pd.concat((autoencoder_test, best_value), ignore_index=True)\n",
    "      \n",
    "    \n",
    "\n",
    "        autoencoder_mse = mean_squared_error(autoencoder_test['D'], X_test['D'])\n",
    "        \n",
    "        y_auto_test = X_test['D'].reset_index()\n",
    "        temp_auto = pd.DataFrame({'y_pred':autoencoder_test['D'], 'y_test':y_auto_test['D']})\n",
    "        \n",
    "        \n",
    "        predictions_auto = pd.concat([predictions_auto,temp_auto], ignore_index=True)\n",
    "        \n",
    "        results_auto[seed] = autoencoder_mse\n",
    "        # print()\n",
    "    results_df = pd.DataFrame(results_auto, index=[0])\n",
    "    plot_boxplot(results_df,save_params)\n",
    "    \n",
    "    print(\"Done!\")"
   ],
   "id": "d7c327a07667c903",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 237: early stopping\n",
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div id='eedf2477-eaaa-42b8-8bee-49c64de1dffa'></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 816us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 285us/step\n",
      "32/32 [==============================] - 0s 282us/step\n",
      "32/32 [==============================] - 0s 310us/step\n",
      "32/32 [==============================] - 0s 328us/step\n",
      "32/32 [==============================] - 0s 368us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 196us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 719us/step\n",
      "32/32 [==============================] - 0s 376us/step\n",
      "32/32 [==============================] - 0s 770us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 465us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 377us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 943us/step\n",
      "32/32 [==============================] - 0s 811us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 317us/step\n",
      "32/32 [==============================] - 0s 345us/step\n",
      "32/32 [==============================] - 0s 363us/step\n",
      "32/32 [==============================] - 0s 390us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 539us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 865us/step\n",
      "32/32 [==============================] - 0s 818us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 343us/step\n",
      "32/32 [==============================] - 0s 373us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 168us/step\n",
      "32/32 [==============================] - 0s 645us/step\n",
      "32/32 [==============================] - 0s 627us/step\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 203: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "\n",
      "Epoch 213: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 218: early stopping\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 536us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 430us/step\n",
      "32/32 [==============================] - 0s 471us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 895us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 362us/step\n",
      "32/32 [==============================] - 0s 399us/step\n",
      "32/32 [==============================] - 0s 435us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 848us/step\n",
      "32/32 [==============================] - 0s 801us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 301us/step\n",
      "32/32 [==============================] - 0s 391us/step\n",
      "32/32 [==============================] - 0s 56us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 869us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 467us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 392us/step\n",
      "32/32 [==============================] - 0s 879us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 345us/step\n",
      "32/32 [==============================] - 0s 374us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 277us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 195: early stopping\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 633us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 312us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 555us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 539us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 238us/step\n",
      "32/32 [==============================] - 0s 257us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 674us/step\n",
      "32/32 [==============================] - 0s 339us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 221us/step\n",
      "32/32 [==============================] - 0s 244us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 583us/step\n",
      "32/32 [==============================] - 0s 540us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 114us/step\n",
      "32/32 [==============================] - 0s 807us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 177us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 624us/step\n",
      "32/32 [==============================] - 0s 614us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 483us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 730us/step\n",
      "32/32 [==============================] - 0s 682us/step\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 369us/step\n",
      "32/32 [==============================] - 0s 198us/step\n",
      "32/32 [==============================] - 0s 427us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 197: early stopping\n",
      "32/32 [==============================] - 0s 581us/step\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 539us/step\n",
      "32/32 [==============================] - 0s 483us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 854us/step\n",
      "32/32 [==============================] - 0s 821us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 444us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 242us/step\n",
      "32/32 [==============================] - 0s 227us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 714us/step\n",
      "32/32 [==============================] - 0s 761us/step\n",
      "32/32 [==============================] - 0s 454us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 186us/step\n",
      "32/32 [==============================] - 0s 209us/step\n",
      "32/32 [==============================] - 0s 231us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 171us/step\n",
      "32/32 [==============================] - 0s 575us/step\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 480us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 173us/step\n",
      "32/32 [==============================] - 0s 581us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 154us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 260us/step\n",
      "32/32 [==============================] - 0s 741us/step\n",
      "32/32 [==============================] - 0s 576us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 721us/step\n",
      "32/32 [==============================] - 0s 690us/step\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 196: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "\n",
      "Epoch 206: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 206: early stopping\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 231us/step\n",
      "32/32 [==============================] - 0s 706us/step\n",
      "32/32 [==============================] - 0s 659us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 139us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 781us/step\n",
      "32/32 [==============================] - 0s 819us/step\n",
      "32/32 [==============================] - 0s 561us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 324us/step\n",
      "32/32 [==============================] - 0s 691us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 449us/step\n",
      "32/32 [==============================] - 0s 479us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 577us/step\n",
      "32/32 [==============================] - 0s 363us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 118us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 653us/step\n",
      "32/32 [==============================] - 0s 619us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 572us/step\n",
      "32/32 [==============================] - 0s 487us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 177us/step\n",
      "32/32 [==============================] - 0s 214us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 678us/step\n",
      "32/32 [==============================] - 0s 609us/step\n",
      "32/32 [==============================] - 0s 568us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 882us/step\n",
      "32/32 [==============================] - 0s 351us/step\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 198: early stopping\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 879us/step\n",
      "32/32 [==============================] - 0s 598us/step\n",
      "32/32 [==============================] - 0s 577us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 269us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 310us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 620us/step\n",
      "32/32 [==============================] - 0s 601us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 896us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 56us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 693us/step\n",
      "32/32 [==============================] - 0s 666us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 427us/step\n",
      "32/32 [==============================] - 0s 464us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 462us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 875us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 232us/step\n",
      "32/32 [==============================] - 0s 300us/step\n",
      "32/32 [==============================] - 0s 331us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 636us/step\n",
      "32/32 [==============================] - 0s 574us/step\n",
      "32/32 [==============================] - 0s 533us/step\n",
      "32/32 [==============================] - 0s 948us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 180: early stopping\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 905us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 418us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 143us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 341us/step\n",
      "32/32 [==============================] - 0s 383us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 462us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 299us/step\n",
      "32/32 [==============================] - 0s 769us/step\n",
      "32/32 [==============================] - 0s 735us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 400us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 471us/step\n",
      "32/32 [==============================] - 0s 311us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 656us/step\n",
      "32/32 [==============================] - 0s 620us/step\n",
      "32/32 [==============================] - 0s 595us/step\n",
      "32/32 [==============================] - 0s 565us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 428us/step\n",
      "32/32 [==============================] - 0s 455us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 690us/step\n",
      "32/32 [==============================] - 0s 670us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 365us/step\n",
      "32/32 [==============================] - 0s 911us/step\n",
      "32/32 [==============================] - 0s 536us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 576us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 186: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 190: early stopping\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "32/32 [==============================] - 0s 440us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 309us/step\n",
      "32/32 [==============================] - 0s 347us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 565us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 202us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "32/32 [==============================] - 0s 457us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 906us/step\n",
      "32/32 [==============================] - 0s 82us/step\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 426us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 146us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 219us/step\n",
      "32/32 [==============================] - 0s 698us/step\n",
      "32/32 [==============================] - 0s 817us/step\n",
      "32/32 [==============================] - 0s 557us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 114us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 897us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 265us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 197: early stopping\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 302us/step\n",
      "32/32 [==============================] - 0s 335us/step\n",
      "32/32 [==============================] - 0s 381us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 564us/step\n",
      "32/32 [==============================] - 0s 534us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 889us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 457us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 888us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 236us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 671us/step\n",
      "32/32 [==============================] - 0s 313us/step\n",
      "32/32 [==============================] - 0s 787us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 352us/step\n",
      "32/32 [==============================] - 0s 386us/step\n",
      "32/32 [==============================] - 0s 415us/step\n",
      "32/32 [==============================] - 0s 556us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 781us/step\n",
      "32/32 [==============================] - 0s 727us/step\n",
      "32/32 [==============================] - 0s 326us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 390us/step\n",
      "32/32 [==============================] - 0s 422us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 275us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 154us/step\n",
      "32/32 [==============================] - 0s 622us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 668us/step\n",
      "32/32 [==============================] - 0s 356us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 166: early stopping\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 831us/step\n",
      "32/32 [==============================] - 0s 810us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 683us/step\n",
      "32/32 [==============================] - 0s 207us/step\n",
      "32/32 [==============================] - 0s 234us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 688us/step\n",
      "32/32 [==============================] - 0s 640us/step\n",
      "32/32 [==============================] - 0s 591us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 342us/step\n",
      "32/32 [==============================] - 0s 384us/step\n",
      "32/32 [==============================] - 0s 398us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 534us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 238us/step\n",
      "32/32 [==============================] - 0s 647us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 522us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 887us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 346us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 429us/step\n",
      "32/32 [==============================] - 0s 534us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 158: early stopping\n",
      "32/32 [==============================] - 0s 748us/step\n",
      "32/32 [==============================] - 0s 728us/step\n",
      "32/32 [==============================] - 0s 669us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 404us/step\n",
      "32/32 [==============================] - 0s 740us/step\n",
      "32/32 [==============================] - 0s 309us/step\n",
      "32/32 [==============================] - 0s 333us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 546us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 227us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 166us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 377us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 444us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 457us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 829us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 353us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 221us/step\n",
      "32/32 [==============================] - 0s 704us/step\n",
      "32/32 [==============================] - 0s 653us/step\n",
      "32/32 [==============================] - 0s 467us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 486us/step\n",
      "32/32 [==============================] - 0s 342us/step\n",
      "32/32 [==============================] - 0s 369us/step\n",
      "32/32 [==============================] - 0s 389us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 153: early stopping\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 802us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 352us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 599us/step\n",
      "32/32 [==============================] - 0s 761us/step\n",
      "32/32 [==============================] - 0s 732us/step\n",
      "32/32 [==============================] - 0s 676us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 439us/step\n",
      "32/32 [==============================] - 0s 462us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 278us/step\n",
      "32/32 [==============================] - 0s 765us/step\n",
      "32/32 [==============================] - 0s 719us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 338us/step\n",
      "32/32 [==============================] - 0s 374us/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 460us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 679us/step\n",
      "32/32 [==============================] - 0s 637us/step\n",
      "32/32 [==============================] - 0s 609us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 190us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 706us/step\n",
      "32/32 [==============================] - 0s 648us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 432us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "32/32 [==============================] - 0s 558us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 479us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 304us/step\n",
      "32/32 [==============================] - 0s 781us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 161: early stopping\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 797us/step\n",
      "32/32 [==============================] - 0s 760us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 333us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 659us/step\n",
      "32/32 [==============================] - 0s 179us/step\n",
      "32/32 [==============================] - 0s 210us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 731us/step\n",
      "32/32 [==============================] - 0s 672us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 82us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 314us/step\n",
      "32/32 [==============================] - 0s 806us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 453us/step\n",
      "32/32 [==============================] - 0s 235us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 671us/step\n",
      "32/32 [==============================] - 0s 622us/step\n",
      "32/32 [==============================] - 0s 595us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 804us/step\n",
      "32/32 [==============================] - 0s 331us/step\n",
      "32/32 [==============================] - 0s 378us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 391us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 782us/step\n",
      "32/32 [==============================] - 0s 742us/step\n",
      "32/32 [==============================] - 0s 698us/step\n",
      "32/32 [==============================] - 0s 344us/step\n",
      "32/32 [==============================] - 0s 649us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 149: early stopping\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 789us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "32/32 [==============================] - 0s 280us/step\n",
      "32/32 [==============================] - 0s 303us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 582us/step\n",
      "32/32 [==============================] - 0s 540us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 446us/step\n",
      "32/32 [==============================] - 0s 851us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 298us/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 582us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 325us/step\n",
      "32/32 [==============================] - 0s 798us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 243us/step\n",
      "32/32 [==============================] - 0s 277us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 113us/step\n",
      "32/32 [==============================] - 0s 578us/step\n",
      "32/32 [==============================] - 0s 799us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 424us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 606us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 219us/step\n",
      "32/32 [==============================] - 0s 242us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 631us/step\n",
      "32/32 [==============================] - 0s 601us/step\n",
      "32/32 [==============================] - 0s 557us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 159: early stopping\n",
      "32/32 [==============================] - 0s 786us/step\n",
      "32/32 [==============================] - 0s 742us/step\n",
      "32/32 [==============================] - 0s 711us/step\n",
      "32/32 [==============================] - 0s 710us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 351us/step\n",
      "32/32 [==============================] - 0s 366us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 839us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 282us/step\n",
      "32/32 [==============================] - 0s 295us/step\n",
      "32/32 [==============================] - 0s 328us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 822us/step\n",
      "32/32 [==============================] - 0s 844us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 826us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 696us/step\n",
      "32/32 [==============================] - 0s 673us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 440us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 332us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 731us/step\n",
      "32/32 [==============================] - 0s 677us/step\n",
      "32/32 [==============================] - 0s 623us/step\n",
      "32/32 [==============================] - 0s 603us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 385us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 143: early stopping\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 134us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 433us/step\n",
      "32/32 [==============================] - 0s 749us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 344us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 146us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 834us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 235us/step\n",
      "32/32 [==============================] - 0s 262us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 663us/step\n",
      "32/32 [==============================] - 0s 704us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 449us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 196us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 886us/step\n",
      "32/32 [==============================] - 0s 863us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 314us/step\n",
      "32/32 [==============================] - 0s 222us/step\n",
      "32/32 [==============================] - 0s 255us/step\n",
      "32/32 [==============================] - 0s 599us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 764us/step\n",
      "32/32 [==============================] - 0s 740us/step\n",
      "32/32 [==============================] - 0s 699us/step\n",
      "32/32 [==============================] - 0s 659us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 170: early stopping\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 562us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 263us/step\n",
      "32/32 [==============================] - 0s 277us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 666us/step\n",
      "32/32 [==============================] - 0s 629us/step\n",
      "32/32 [==============================] - 0s 584us/step\n",
      "32/32 [==============================] - 0s 547us/step\n",
      "32/32 [==============================] - 0s 467us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 389us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 227us/step\n",
      "32/32 [==============================] - 0s 252us/step\n",
      "32/32 [==============================] - 0s 268us/step\n",
      "32/32 [==============================] - 0s 443us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 660us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 185us/step\n",
      "32/32 [==============================] - 0s 212us/step\n",
      "32/32 [==============================] - 0s 375us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 604us/step\n",
      "32/32 [==============================] - 0s 582us/step\n",
      "32/32 [==============================] - 0s 487us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 367us/step\n",
      "32/32 [==============================] - 0s 410us/step\n",
      "32/32 [==============================] - 0s 422us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 864us/step\n",
      "32/32 [==============================] - 0s 616us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 538us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 64us/step\n",
      "32/32 [==============================] - 0s 318us/step\n",
      "32/32 [==============================] - 0s 369us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 190: early stopping\n",
      "32/32 [==============================] - 0s 398us/step\n",
      "32/32 [==============================] - 0s 448us/step\n",
      "32/32 [==============================] - 0s 318us/step\n",
      "32/32 [==============================] - 0s 601us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 954us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 289us/step\n",
      "32/32 [==============================] - 0s 767us/step\n",
      "32/32 [==============================] - 0s 747us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 459us/step\n",
      "32/32 [==============================] - 0s 486us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 698us/step\n",
      "32/32 [==============================] - 0s 682us/step\n",
      "32/32 [==============================] - 0s 642us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 455us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 633us/step\n",
      "32/32 [==============================] - 0s 178us/step\n",
      "32/32 [==============================] - 0s 213us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 686us/step\n",
      "32/32 [==============================] - 0s 856us/step\n",
      "32/32 [==============================] - 0s 617us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 356us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 423us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 541us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 716us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 542us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 159: early stopping\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 605us/step\n",
      "32/32 [==============================] - 0s 575us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 732us/step\n",
      "32/32 [==============================] - 0s 693us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 414us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 486us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 745us/step\n",
      "32/32 [==============================] - 0s 701us/step\n",
      "32/32 [==============================] - 0s 610us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 815us/step\n",
      "32/32 [==============================] - 0s 320us/step\n",
      "32/32 [==============================] - 0s 369us/step\n",
      "32/32 [==============================] - 0s 395us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 541us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 431us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 681us/step\n",
      "32/32 [==============================] - 0s 650us/step\n",
      "32/32 [==============================] - 0s 599us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 186: early stopping\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 300us/step\n",
      "32/32 [==============================] - 0s 311us/step\n",
      "32/32 [==============================] - 0s 469us/step\n",
      "32/32 [==============================] - 0s 108us/step\n",
      "32/32 [==============================] - 0s 575us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 251us/step\n",
      "32/32 [==============================] - 0s 260us/step\n",
      "32/32 [==============================] - 0s 300us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 663us/step\n",
      "32/32 [==============================] - 0s 725us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 428us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 460us/step\n",
      "32/32 [==============================] - 0s 808us/step\n",
      "32/32 [==============================] - 0s 782us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 325us/step\n",
      "32/32 [==============================] - 0s 349us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 622us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 845us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 318us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 733us/step\n",
      "32/32 [==============================] - 0s 697us/step\n",
      "32/32 [==============================] - 0s 655us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 147us/step\n",
      "32/32 [==============================] - 0s 608us/step\n",
      "32/32 [==============================] - 0s 575us/step\n",
      "32/32 [==============================] - 0s 548us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 181: early stopping\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 433us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 902us/step\n",
      "32/32 [==============================] - 0s 579us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 808us/step\n",
      "32/32 [==============================] - 0s 768us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 615us/step\n",
      "32/32 [==============================] - 0s 379us/step\n",
      "32/32 [==============================] - 0s 339us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 658us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 603us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 444us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 629us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 898us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 399us/step\n",
      "32/32 [==============================] - 0s 432us/step\n",
      "32/32 [==============================] - 0s 456us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 868us/step\n",
      "32/32 [==============================] - 0s 563us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 164: early stopping\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 841us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 829us/step\n",
      "32/32 [==============================] - 0s 809us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 487us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 534us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 246us/step\n",
      "32/32 [==============================] - 0s 281us/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 734us/step\n",
      "32/32 [==============================] - 0s 701us/step\n",
      "32/32 [==============================] - 0s 662us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 734us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 130us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 342us/step\n",
      "32/32 [==============================] - 0s 345us/step\n",
      "32/32 [==============================] - 0s 801us/step\n",
      "32/32 [==============================] - 0s 774us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 326us/step\n",
      "32/32 [==============================] - 0s 356us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 195: early stopping\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 242us/step\n",
      "32/32 [==============================] - 0s 282us/step\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 646us/step\n",
      "32/32 [==============================] - 0s 902us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 857us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 298us/step\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 209us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 686us/step\n",
      "32/32 [==============================] - 0s 654us/step\n",
      "32/32 [==============================] - 0s 624us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 854us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 172us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 212us/step\n",
      "32/32 [==============================] - 0s 683us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 364us/step\n",
      "32/32 [==============================] - 0s 279us/step\n",
      "32/32 [==============================] - 0s 298us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 560us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 363us/step\n",
      "32/32 [==============================] - 0s 825us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 332us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 246us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 695us/step\n",
      "32/32 [==============================] - 0s 679us/step\n",
      "32/32 [==============================] - 0s 646us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 427us/step\n",
      "32/32 [==============================] - 0s 467us/step\n",
      "32/32 [==============================] - 0s 347us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 132: early stopping\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 282us/step\n",
      "32/32 [==============================] - 0s 314us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 635us/step\n",
      "32/32 [==============================] - 0s 581us/step\n",
      "32/32 [==============================] - 0s 535us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 814us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 243us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 339us/step\n",
      "32/32 [==============================] - 0s 131us/step\n",
      "32/32 [==============================] - 0s 598us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 695us/step\n",
      "32/32 [==============================] - 0s 664us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 451us/step\n",
      "32/32 [==============================] - 0s 479us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 930us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 331us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 390us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 555us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 833us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 318us/step\n",
      "32/32 [==============================] - 0s 354us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 785us/step\n",
      "32/32 [==============================] - 0s 754us/step\n",
      "32/32 [==============================] - 0s 716us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 182: early stopping\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 813us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 334us/step\n",
      "32/32 [==============================] - 0s 808us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 347us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 239us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 671us/step\n",
      "32/32 [==============================] - 0s 639us/step\n",
      "32/32 [==============================] - 0s 614us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 464us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 159us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 752us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 773us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 330us/step\n",
      "32/32 [==============================] - 0s 375us/step\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 547us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 618us/step\n",
      "32/32 [==============================] - 0s 569us/step\n",
      "32/32 [==============================] - 0s 535us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 537us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 925us/step\n",
      "32/32 [==============================] - 0s 890us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 67: early stopping\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 816us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 415us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 896us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 260us/step\n",
      "32/32 [==============================] - 0s 715us/step\n",
      "32/32 [==============================] - 0s 661us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 440us/step\n",
      "32/32 [==============================] - 0s 459us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 377us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 762us/step\n",
      "32/32 [==============================] - 0s 712us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 396us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 856us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 438us/step\n",
      "32/32 [==============================] - 0s 482us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 826us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 305us/step\n",
      "32/32 [==============================] - 0s 341us/step\n",
      "32/32 [==============================] - 0s 116us/step\n",
      "32/32 [==============================] - 0s 571us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 378us/step\n",
      "32/32 [==============================] - 0s 794us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 532us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 155: early stopping\n",
      "32/32 [==============================] - 0s 473us/step\n",
      "32/32 [==============================] - 0s 553us/step\n",
      "32/32 [==============================] - 0s 396us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 923us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 415us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 918us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 142us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 733us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 249us/step\n",
      "32/32 [==============================] - 0s 273us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 641us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 234us/step\n",
      "32/32 [==============================] - 0s 268us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 450us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 260us/step\n",
      "32/32 [==============================] - 0s 719us/step\n",
      "32/32 [==============================] - 0s 667us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 187: early stopping\n",
      "32/32 [==============================] - 0s 56us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 272us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 173us/step\n",
      "32/32 [==============================] - 0s 296us/step\n",
      "32/32 [==============================] - 0s 614us/step\n",
      "32/32 [==============================] - 0s 561us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 405us/step\n",
      "32/32 [==============================] - 0s 441us/step\n",
      "32/32 [==============================] - 0s 556us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 139us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 806us/step\n",
      "32/32 [==============================] - 0s 765us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 244us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 603us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 206us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 292us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 124us/step\n",
      "32/32 [==============================] - 0s 605us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 325us/step\n",
      "32/32 [==============================] - 0s 645us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 456us/step\n",
      "32/32 [==============================] - 0s 475us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 176: early stopping\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 814us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 356us/step\n",
      "32/32 [==============================] - 0s 376us/step\n",
      "32/32 [==============================] - 0s 857us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 825us/step\n",
      "32/32 [==============================] - 0s 794us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 686us/step\n",
      "32/32 [==============================] - 0s 765us/step\n",
      "32/32 [==============================] - 0s 605us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 445us/step\n",
      "32/32 [==============================] - 0s 466us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 219us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 701us/step\n",
      "32/32 [==============================] - 0s 660us/step\n",
      "32/32 [==============================] - 0s 623us/step\n",
      "32/32 [==============================] - 0s 606us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 683us/step\n",
      "32/32 [==============================] - 0s 815us/step\n",
      "32/32 [==============================] - 0s 880us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 374us/step\n",
      "32/32 [==============================] - 0s 719us/step\n",
      "32/32 [==============================] - 0s 777us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 166us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 629us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 170: early stopping\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 547us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 549us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 208us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 677us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 759us/step\n",
      "32/32 [==============================] - 0s 703us/step\n",
      "32/32 [==============================] - 0s 680us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 407us/step\n",
      "32/32 [==============================] - 0s 447us/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 120us/step\n",
      "32/32 [==============================] - 0s 605us/step\n",
      "32/32 [==============================] - 0s 578us/step\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 354us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 863us/step\n",
      "32/32 [==============================] - 0s 659us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 429us/step\n",
      "32/32 [==============================] - 0s 453us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 135us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 572us/step\n",
      "32/32 [==============================] - 0s 546us/step\n",
      "32/32 [==============================] - 0s 556us/step\n",
      "32/32 [==============================] - 0s 522us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 575us/step\n",
      "32/32 [==============================] - 0s 614us/step\n",
      "32/32 [==============================] - 0s 563us/step\n",
      "32/32 [==============================] - 0s 534us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 148: early stopping\n",
      "32/32 [==============================] - 0s 718us/step\n",
      "32/32 [==============================] - 0s 677us/step\n",
      "32/32 [==============================] - 0s 648us/step\n",
      "32/32 [==============================] - 0s 618us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 454us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 348us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "32/32 [==============================] - 0s 441us/step\n",
      "32/32 [==============================] - 0s 555us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 524us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 891us/step\n",
      "32/32 [==============================] - 0s 249us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 309us/step\n",
      "32/32 [==============================] - 0s 792us/step\n",
      "32/32 [==============================] - 0s 734us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 358us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 855us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 46us/step\n",
      "32/32 [==============================] - 0s 411us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 473us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 396us/step\n",
      "32/32 [==============================] - 0s 709us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 399us/step\n",
      "32/32 [==============================] - 0s 450us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 572us/step\n",
      "32/32 [==============================] - 0s 553us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 178: early stopping\n",
      "32/32 [==============================] - 0s 381us/step\n",
      "32/32 [==============================] - 0s 430us/step\n",
      "32/32 [==============================] - 0s 465us/step\n",
      "32/32 [==============================] - 0s 230us/step\n",
      "32/32 [==============================] - 0s 264us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 660us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 748us/step\n",
      "32/32 [==============================] - 0s 709us/step\n",
      "32/32 [==============================] - 0s 664us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 567us/step\n",
      "32/32 [==============================] - 0s 427us/step\n",
      "32/32 [==============================] - 0s 440us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 558us/step\n",
      "32/32 [==============================] - 0s 532us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 146us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 769us/step\n",
      "32/32 [==============================] - 0s 405us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 928us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 204us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 617us/step\n",
      "32/32 [==============================] - 0s 579us/step\n",
      "32/32 [==============================] - 0s 549us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 350us/step\n",
      "32/32 [==============================] - 0s 384us/step\n",
      "32/32 [==============================] - 0s 417us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 553us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 181: early stopping\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 150us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 618us/step\n",
      "32/32 [==============================] - 0s 573us/step\n",
      "32/32 [==============================] - 0s 541us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 224us/step\n",
      "32/32 [==============================] - 0s 251us/step\n",
      "32/32 [==============================] - 0s 279us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 156us/step\n",
      "32/32 [==============================] - 0s 613us/step\n",
      "32/32 [==============================] - 0s 594us/step\n",
      "32/32 [==============================] - 0s 619us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 429us/step\n",
      "32/32 [==============================] - 0s 705us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 171us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 592us/step\n",
      "32/32 [==============================] - 0s 557us/step\n",
      "32/32 [==============================] - 0s 548us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 281us/step\n",
      "32/32 [==============================] - 0s 305us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 639us/step\n",
      "32/32 [==============================] - 0s 607us/step\n",
      "32/32 [==============================] - 0s 586us/step\n",
      "32/32 [==============================] - 0s 561us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 180: early stopping\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 206us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 716us/step\n",
      "32/32 [==============================] - 0s 609us/step\n",
      "32/32 [==============================] - 0s 571us/step\n",
      "32/32 [==============================] - 0s 528us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 120us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 618us/step\n",
      "32/32 [==============================] - 0s 647us/step\n",
      "32/32 [==============================] - 0s 642us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 430us/step\n",
      "32/32 [==============================] - 0s 482us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 229us/step\n",
      "32/32 [==============================] - 0s 264us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 188us/step\n",
      "32/32 [==============================] - 0s 658us/step\n",
      "32/32 [==============================] - 0s 631us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 158us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 801us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 350us/step\n",
      "32/32 [==============================] - 0s 379us/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 587us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 170: early stopping\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 303us/step\n",
      "32/32 [==============================] - 0s 325us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 633us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 564us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 545us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 580us/step\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 351us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 414us/step\n",
      "32/32 [==============================] - 0s 586us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 487us/step\n",
      "32/32 [==============================] - 0s 679us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 440us/step\n",
      "32/32 [==============================] - 0s 478us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 82us/step\n",
      "32/32 [==============================] - 0s 573us/step\n",
      "32/32 [==============================] - 0s 541us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 172us/step\n",
      "32/32 [==============================] - 0s 209us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 204us/step\n",
      "32/32 [==============================] - 0s 681us/step\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 161: early stopping\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 798us/step\n",
      "32/32 [==============================] - 0s 823us/step\n",
      "32/32 [==============================] - 0s 734us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 454us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 259us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 866us/step\n",
      "32/32 [==============================] - 0s 767us/step\n",
      "32/32 [==============================] - 0s 745us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 150us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 706us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 809us/step\n",
      "32/32 [==============================] - 0s 792us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 754us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 107us/step\n",
      "32/32 [==============================] - 0s 152us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 814us/step\n",
      "32/32 [==============================] - 0s 786us/step\n",
      "32/32 [==============================] - 0s 752us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 377us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 111us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 159: early stopping\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 238us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 177us/step\n",
      "32/32 [==============================] - 0s 650us/step\n",
      "32/32 [==============================] - 0s 628us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 724us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 399us/step\n",
      "32/32 [==============================] - 0s 409us/step\n",
      "32/32 [==============================] - 0s 432us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 185us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 531us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 312us/step\n",
      "32/32 [==============================] - 0s 774us/step\n",
      "32/32 [==============================] - 0s 755us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 455us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 710us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 471us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 257us/step\n",
      "32/32 [==============================] - 0s 283us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 910us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 186: early stopping\n",
      "32/32 [==============================] - 0s 113us/step\n",
      "32/32 [==============================] - 0s 525us/step\n",
      "32/32 [==============================] - 0s 195us/step\n",
      "32/32 [==============================] - 0s 211us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 709us/step\n",
      "32/32 [==============================] - 0s 314us/step\n",
      "32/32 [==============================] - 0s 810us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 329us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 354us/step\n",
      "32/32 [==============================] - 0s 386us/step\n",
      "32/32 [==============================] - 0s 432us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 615us/step\n",
      "32/32 [==============================] - 0s 598us/step\n",
      "32/32 [==============================] - 0s 569us/step\n",
      "32/32 [==============================] - 0s 531us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 264us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 280us/step\n",
      "32/32 [==============================] - 0s 306us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 140us/step\n",
      "32/32 [==============================] - 0s 611us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 531us/step\n",
      "32/32 [==============================] - 0s 43us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 426us/step\n",
      "32/32 [==============================] - 0s 630us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 720us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 449us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 147us/step\n",
      "32/32 [==============================] - 0s 582us/step\n",
      "32/32 [==============================] - 0s 545us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 126us/step\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 162: early stopping\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 314us/step\n",
      "32/32 [==============================] - 0s 277us/step\n",
      "32/32 [==============================] - 0s 302us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 404us/step\n",
      "32/32 [==============================] - 0s 409us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 632us/step\n",
      "32/32 [==============================] - 0s 274us/step\n",
      "32/32 [==============================] - 0s 299us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 426us/step\n",
      "32/32 [==============================] - 0s 878us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 391us/step\n",
      "32/32 [==============================] - 0s 437us/step\n",
      "32/32 [==============================] - 0s 475us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 182us/step\n",
      "32/32 [==============================] - 0s 197us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 831us/step\n",
      "32/32 [==============================] - 0s 579us/step\n",
      "32/32 [==============================] - 0s 537us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 353us/step\n",
      "32/32 [==============================] - 0s 375us/step\n",
      "32/32 [==============================] - 0s 85us/step\n",
      "32/32 [==============================] - 0s 571us/step\n",
      "32/32 [==============================] - 0s 536us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 178: early stopping\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 471us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 174us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 289us/step\n",
      "32/32 [==============================] - 0s 768us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 64us/step\n",
      "32/32 [==============================] - 0s 316us/step\n",
      "32/32 [==============================] - 0s 350us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 620us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 560us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 690us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 242us/step\n",
      "32/32 [==============================] - 0s 283us/step\n",
      "32/32 [==============================] - 0s 648us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 765us/step\n",
      "32/32 [==============================] - 0s 780us/step\n",
      "32/32 [==============================] - 0s 699us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 547us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 375us/step\n",
      "32/32 [==============================] - 0s 375us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 702us/step\n",
      "32/32 [==============================] - 0s 553us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 137us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 157: early stopping\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 568us/step\n",
      "32/32 [==============================] - 0s 524us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 902us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 275us/step\n",
      "32/32 [==============================] - 0s 336us/step\n",
      "32/32 [==============================] - 0s 349us/step\n",
      "32/32 [==============================] - 0s 381us/step\n",
      "32/32 [==============================] - 0s 99us/step\n",
      "32/32 [==============================] - 0s 577us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 636us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 407us/step\n",
      "32/32 [==============================] - 0s 439us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 145us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 914us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 449us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 252us/step\n",
      "32/32 [==============================] - 0s 288us/step\n",
      "32/32 [==============================] - 0s 337us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 557us/step\n",
      "32/32 [==============================] - 0s 288us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 929us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 192us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 146us/step\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 194: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 198: early stopping\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 567us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 326us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 623us/step\n",
      "32/32 [==============================] - 0s 603us/step\n",
      "32/32 [==============================] - 0s 564us/step\n",
      "32/32 [==============================] - 0s 544us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 163us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 185us/step\n",
      "32/32 [==============================] - 0s 212us/step\n",
      "32/32 [==============================] - 0s 274us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 649us/step\n",
      "32/32 [==============================] - 0s 298us/step\n",
      "32/32 [==============================] - 0s 582us/step\n",
      "32/32 [==============================] - 0s 560us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 349us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 610us/step\n",
      "32/32 [==============================] - 0s 591us/step\n",
      "32/32 [==============================] - 0s 571us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 66us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 338us/step\n",
      "32/32 [==============================] - 0s 360us/step\n",
      "32/32 [==============================] - 0s 393us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 465us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 153us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 182: early stopping\n",
      "32/32 [==============================] - 0s 210us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 812us/step\n",
      "32/32 [==============================] - 0s 725us/step\n",
      "32/32 [==============================] - 0s 695us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 648us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 124us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 185us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 575us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 285us/step\n",
      "32/32 [==============================] - 0s 312us/step\n",
      "32/32 [==============================] - 0s 342us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 115us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 706us/step\n",
      "32/32 [==============================] - 0s 539us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 631us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 353us/step\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 178us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 820us/step\n",
      "32/32 [==============================] - 0s 776us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 473us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 834us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 184: early stopping\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 670us/step\n",
      "32/32 [==============================] - 0s 639us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 546us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 335us/step\n",
      "32/32 [==============================] - 0s 341us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 595us/step\n",
      "32/32 [==============================] - 0s 576us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 884us/step\n",
      "32/32 [==============================] - 0s 764us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 362us/step\n",
      "32/32 [==============================] - 0s 113us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 779us/step\n",
      "32/32 [==============================] - 0s 755us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 179us/step\n",
      "32/32 [==============================] - 0s 594us/step\n",
      "32/32 [==============================] - 0s 563us/step\n",
      "32/32 [==============================] - 0s 528us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 173: early stopping\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 66us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 260us/step\n",
      "32/32 [==============================] - 0s 598us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 114us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 635us/step\n",
      "32/32 [==============================] - 0s 582us/step\n",
      "32/32 [==============================] - 0s 537us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 178us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 807us/step\n",
      "32/32 [==============================] - 0s 767us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 453us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 210us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 800us/step\n",
      "32/32 [==============================] - 0s 754us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 356us/step\n",
      "32/32 [==============================] - 0s 384us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 191: early stopping\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 640us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 451us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 645us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 564us/step\n",
      "32/32 [==============================] - 0s 599us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 454us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 192us/step\n",
      "32/32 [==============================] - 0s 213us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 703us/step\n",
      "32/32 [==============================] - 0s 227us/step\n",
      "32/32 [==============================] - 0s 533us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 454us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 195us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 407us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 438us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 177: early stopping\n",
      "32/32 [==============================] - 0s 737us/step\n",
      "32/32 [==============================] - 0s 350us/step\n",
      "32/32 [==============================] - 0s 810us/step\n",
      "32/32 [==============================] - 0s 758us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 391us/step\n",
      "32/32 [==============================] - 0s 407us/step\n",
      "32/32 [==============================] - 0s 453us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 833us/step\n",
      "32/32 [==============================] - 0s 806us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 278us/step\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 287us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 145us/step\n",
      "32/32 [==============================] - 0s 618us/step\n",
      "32/32 [==============================] - 0s 579us/step\n",
      "32/32 [==============================] - 0s 531us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 243us/step\n",
      "32/32 [==============================] - 0s 259us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 627us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 353us/step\n",
      "32/32 [==============================] - 0s 832us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 285us/step\n",
      "32/32 [==============================] - 0s 305us/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 699us/step\n",
      "32/32 [==============================] - 0s 655us/step\n",
      "32/32 [==============================] - 0s 630us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 456us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 445us/step\n",
      "32/32 [==============================] - 0s 481us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 58: early stopping\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "32/32 [==============================] - 0s 428us/step\n",
      "32/32 [==============================] - 0s 482us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 179us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 894us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 264us/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 369us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 84us/step\n",
      "32/32 [==============================] - 0s 572us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 470us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 579us/step\n",
      "32/32 [==============================] - 0s 540us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 547us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 199us/step\n",
      "32/32 [==============================] - 0s 672us/step\n",
      "32/32 [==============================] - 0s 622us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 569us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 159: early stopping\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 525us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 431us/step\n",
      "32/32 [==============================] - 0s 111us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 546us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 324us/step\n",
      "32/32 [==============================] - 0s 595us/step\n",
      "32/32 [==============================] - 0s 562us/step\n",
      "32/32 [==============================] - 0s 531us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 331us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 101us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 194us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 274us/step\n",
      "32/32 [==============================] - 0s 304us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 339us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 157: early stopping\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 339us/step\n",
      "32/32 [==============================] - 0s 352us/step\n",
      "32/32 [==============================] - 0s 834us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 642us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 330us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 395us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 136us/step\n",
      "32/32 [==============================] - 0s 628us/step\n",
      "32/32 [==============================] - 0s 598us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 525us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 455us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 833us/step\n",
      "32/32 [==============================] - 0s 813us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 327us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 606us/step\n",
      "32/32 [==============================] - 0s 587us/step\n",
      "32/32 [==============================] - 0s 557us/step\n",
      "32/32 [==============================] - 0s 724us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 164: early stopping\n",
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div id='4495a387-7bee-4ba1-89e5-7ededad4993d'></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 486us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 483us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 348us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 99us/step\n",
      "32/32 [==============================] - 0s 555us/step\n",
      "32/32 [==============================] - 0s 535us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "32/32 [==============================] - 0s 453us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 783us/step\n",
      "32/32 [==============================] - 0s 682us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 525us/step\n",
      "32/32 [==============================] - 0s 177us/step\n",
      "32/32 [==============================] - 0s 203us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 524us/step\n",
      "32/32 [==============================] - 0s 679us/step\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 365us/step\n",
      "32/32 [==============================] - 0s 102us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 731us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 862us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 265us/step\n",
      "32/32 [==============================] - 0s 295us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 139us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 170: early stopping\n",
      "32/32 [==============================] - 0s 610us/step\n",
      "32/32 [==============================] - 0s 574us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 483us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 743us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 352us/step\n",
      "32/32 [==============================] - 0s 366us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 860us/step\n",
      "32/32 [==============================] - 0s 825us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 288us/step\n",
      "32/32 [==============================] - 0s 466us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 721us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 429us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 166us/step\n",
      "32/32 [==============================] - 0s 331us/step\n",
      "32/32 [==============================] - 0s 138us/step\n",
      "32/32 [==============================] - 0s 631us/step\n",
      "32/32 [==============================] - 0s 585us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 310us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 737us/step\n",
      "32/32 [==============================] - 0s 680us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 440us/step\n",
      "32/32 [==============================] - 0s 482us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 735us/step\n",
      "32/32 [==============================] - 0s 668us/step\n",
      "32/32 [==============================] - 0s 618us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 745us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 165: early stopping\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 430us/step\n",
      "32/32 [==============================] - 0s 449us/step\n",
      "32/32 [==============================] - 0s 458us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 772us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 342us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 446us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 714us/step\n",
      "32/32 [==============================] - 0s 680us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 443us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 764us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 335us/step\n",
      "32/32 [==============================] - 0s 358us/step\n",
      "32/32 [==============================] - 0s 405us/step\n",
      "32/32 [==============================] - 0s 82us/step\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 663us/step\n",
      "32/32 [==============================] - 0s 620us/step\n",
      "32/32 [==============================] - 0s 579us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 718us/step\n",
      "32/32 [==============================] - 0s 671us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "32/32 [==============================] - 0s 469us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 195us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 607us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 445us/step\n",
      "32/32 [==============================] - 0s 475us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 361us/step\n",
      "32/32 [==============================] - 0s 707us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 195: early stopping\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 391us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 280us/step\n",
      "32/32 [==============================] - 0s 292us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 650us/step\n",
      "32/32 [==============================] - 0s 732us/step\n",
      "32/32 [==============================] - 0s 559us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 167us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 722us/step\n",
      "32/32 [==============================] - 0s 700us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 404us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 528us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 607us/step\n",
      "32/32 [==============================] - 0s 469us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 913us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 797us/step\n",
      "32/32 [==============================] - 0s 749us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 356us/step\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "32/32 [==============================] - 0s 193us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 716us/step\n",
      "32/32 [==============================] - 0s 657us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 431us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 338us/step\n",
      "32/32 [==============================] - 0s 131us/step\n",
      "32/32 [==============================] - 0s 608us/step\n",
      "32/32 [==============================] - 0s 560us/step\n",
      "32/32 [==============================] - 0s 522us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 173: early stopping\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 164us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 739us/step\n",
      "32/32 [==============================] - 0s 607us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 464us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 372us/step\n",
      "32/32 [==============================] - 0s 399us/step\n",
      "32/32 [==============================] - 0s 442us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 434us/step\n",
      "32/32 [==============================] - 0s 464us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 851us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 353us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 237us/step\n",
      "32/32 [==============================] - 0s 266us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 653us/step\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 549us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 381us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 522us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 479us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 475us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 159: early stopping\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 320us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 311us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 106us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 555us/step\n",
      "32/32 [==============================] - 0s 537us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 877us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 233us/step\n",
      "32/32 [==============================] - 0s 264us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 660us/step\n",
      "32/32 [==============================] - 0s 641us/step\n",
      "32/32 [==============================] - 0s 605us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 376us/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "32/32 [==============================] - 0s 460us/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 866us/step\n",
      "32/32 [==============================] - 0s 815us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 281us/step\n",
      "32/32 [==============================] - 0s 297us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 292us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 427us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 223us/step\n",
      "32/32 [==============================] - 0s 259us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 778us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 156: early stopping\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 547us/step\n",
      "32/32 [==============================] - 0s 381us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 532us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 847us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 432us/step\n",
      "32/32 [==============================] - 0s 469us/step\n",
      "32/32 [==============================] - 0s 534us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 951us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 119us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 605us/step\n",
      "32/32 [==============================] - 0s 550us/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 538us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 88us/step\n",
      "32/32 [==============================] - 0s 130us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 320us/step\n",
      "32/32 [==============================] - 0s 794us/step\n",
      "32/32 [==============================] - 0s 745us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 273us/step\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 184: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 184: early stopping\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 711us/step\n",
      "32/32 [==============================] - 0s 673us/step\n",
      "32/32 [==============================] - 0s 565us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 130us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 467us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 861us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 274us/step\n",
      "32/32 [==============================] - 0s 314us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 238us/step\n",
      "32/32 [==============================] - 0s 700us/step\n",
      "32/32 [==============================] - 0s 663us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 433us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "32/32 [==============================] - 0s 455us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 551us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 888us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 181us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 706us/step\n",
      "32/32 [==============================] - 0s 687us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 375us/step\n",
      "32/32 [==============================] - 0s 116us/step\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 170: early stopping\n",
      "32/32 [==============================] - 0s 129us/step\n",
      "32/32 [==============================] - 0s 250us/step\n",
      "32/32 [==============================] - 0s 280us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 658us/step\n",
      "32/32 [==============================] - 0s 635us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 424us/step\n",
      "32/32 [==============================] - 0s 594us/step\n",
      "32/32 [==============================] - 0s 564us/step\n",
      "32/32 [==============================] - 0s 537us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 419us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 268us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 170us/step\n",
      "32/32 [==============================] - 0s 651us/step\n",
      "32/32 [==============================] - 0s 583us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "32/32 [==============================] - 0s 384us/step\n",
      "32/32 [==============================] - 0s 420us/step\n",
      "32/32 [==============================] - 0s 573us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 701us/step\n",
      "32/32 [==============================] - 0s 238us/step\n",
      "32/32 [==============================] - 0s 286us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 145us/step\n",
      "32/32 [==============================] - 0s 626us/step\n",
      "32/32 [==============================] - 0s 568us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 397us/step\n",
      "32/32 [==============================] - 0s 410us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 529us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 488us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 354us/step\n",
      "32/32 [==============================] - 0s 103us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 546us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 153: early stopping\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 235us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 174us/step\n",
      "32/32 [==============================] - 0s 293us/step\n",
      "32/32 [==============================] - 0s 767us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 332us/step\n",
      "32/32 [==============================] - 0s 370us/step\n",
      "32/32 [==============================] - 0s 607us/step\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 659us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 467us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 288us/step\n",
      "32/32 [==============================] - 0s 712us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 295us/step\n",
      "32/32 [==============================] - 0s 319us/step\n",
      "32/32 [==============================] - 0s 349us/step\n",
      "32/32 [==============================] - 0s 131us/step\n",
      "32/32 [==============================] - 0s 858us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 851us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 275us/step\n",
      "32/32 [==============================] - 0s 297us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 115us/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 241us/step\n",
      "32/32 [==============================] - 0s 702us/step\n",
      "32/32 [==============================] - 0s 630us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 454us/step\n",
      "32/32 [==============================] - 0s 464us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 132us/step\n",
      "32/32 [==============================] - 0s 597us/step\n",
      "32/32 [==============================] - 0s 556us/step\n",
      "32/32 [==============================] - 0s 525us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "32/32 [==============================] - 0s 606us/step\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 177: early stopping\n",
      "32/32 [==============================] - 0s 258us/step\n",
      "32/32 [==============================] - 0s 300us/step\n",
      "32/32 [==============================] - 0s 333us/step\n",
      "32/32 [==============================] - 0s 366us/step\n",
      "32/32 [==============================] - 0s 108us/step\n",
      "32/32 [==============================] - 0s 594us/step\n",
      "32/32 [==============================] - 0s 678us/step\n",
      "32/32 [==============================] - 0s 683us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 408us/step\n",
      "32/32 [==============================] - 0s 445us/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 465us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 292us/step\n",
      "32/32 [==============================] - 0s 325us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 639us/step\n",
      "32/32 [==============================] - 0s 599us/step\n",
      "32/32 [==============================] - 0s 567us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 343us/step\n",
      "32/32 [==============================] - 0s 386us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 883us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 260us/step\n",
      "32/32 [==============================] - 0s 295us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 157us/step\n",
      "32/32 [==============================] - 0s 613us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 367us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "32/32 [==============================] - 0s 449us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 818us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 82us/step\n",
      "32/32 [==============================] - 0s 427us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 325us/step\n",
      "32/32 [==============================] - 0s 792us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 184: early stopping\n",
      "32/32 [==============================] - 0s 531us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 777us/step\n",
      "32/32 [==============================] - 0s 730us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 366us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 462us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 653us/step\n",
      "32/32 [==============================] - 0s 626us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 457us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 225us/step\n",
      "32/32 [==============================] - 0s 705us/step\n",
      "32/32 [==============================] - 0s 677us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 414us/step\n",
      "32/32 [==============================] - 0s 462us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 640us/step\n",
      "32/32 [==============================] - 0s 607us/step\n",
      "32/32 [==============================] - 0s 592us/step\n",
      "32/32 [==============================] - 0s 442us/step\n",
      "32/32 [==============================] - 0s 473us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 236us/step\n",
      "32/32 [==============================] - 0s 720us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 370us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 430us/step\n",
      "32/32 [==============================] - 0s 926us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 830us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 284us/step\n",
      "32/32 [==============================] - 0s 287us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 158: early stopping\n",
      "32/32 [==============================] - 0s 392us/step\n",
      "32/32 [==============================] - 0s 431us/step\n",
      "32/32 [==============================] - 0s 448us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 217us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 729us/step\n",
      "32/32 [==============================] - 0s 702us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 394us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 787us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 235us/step\n",
      "32/32 [==============================] - 0s 265us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 685us/step\n",
      "32/32 [==============================] - 0s 672us/step\n",
      "32/32 [==============================] - 0s 635us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 363us/step\n",
      "32/32 [==============================] - 0s 398us/step\n",
      "32/32 [==============================] - 0s 438us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 791us/step\n",
      "32/32 [==============================] - 0s 754us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 319us/step\n",
      "32/32 [==============================] - 0s 335us/step\n",
      "32/32 [==============================] - 0s 370us/step\n",
      "32/32 [==============================] - 0s 383us/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 210us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 837us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 305us/step\n",
      "32/32 [==============================] - 0s 321us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 499us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 158: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 174: early stopping\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 491us/step\n",
      "32/32 [==============================] - 0s 366us/step\n",
      "32/32 [==============================] - 0s 721us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 410us/step\n",
      "32/32 [==============================] - 0s 451us/step\n",
      "32/32 [==============================] - 0s 544us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 783us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 335us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 376us/step\n",
      "32/32 [==============================] - 0s 615us/step\n",
      "32/32 [==============================] - 0s 823us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 221us/step\n",
      "32/32 [==============================] - 0s 259us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 195us/step\n",
      "32/32 [==============================] - 0s 560us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 479us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 147us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 625us/step\n",
      "32/32 [==============================] - 0s 577us/step\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 533us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 251us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 663us/step\n",
      "32/32 [==============================] - 0s 615us/step\n",
      "32/32 [==============================] - 0s 569us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 97us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 144: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 168: early stopping\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 386us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 442us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 496us/step\n",
      "32/32 [==============================] - 0s 814us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 280us/step\n",
      "32/32 [==============================] - 0s 310us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 601us/step\n",
      "32/32 [==============================] - 0s 695us/step\n",
      "32/32 [==============================] - 0s 672us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 398us/step\n",
      "32/32 [==============================] - 0s 422us/step\n",
      "32/32 [==============================] - 0s 476us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 373us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 327us/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 99us/step\n",
      "32/32 [==============================] - 0s 588us/step\n",
      "32/32 [==============================] - 0s 561us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 253us/step\n",
      "32/32 [==============================] - 0s 279us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 673us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 196us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 190us/step\n",
      "32/32 [==============================] - 0s 230us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 854us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 174: early stopping\n",
      "32/32 [==============================] - 0s 433us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 384us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 573us/step\n",
      "32/32 [==============================] - 0s 521us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 878us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 358us/step\n",
      "32/32 [==============================] - 0s 406us/step\n",
      "32/32 [==============================] - 0s 469us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 752us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 457us/step\n",
      "32/32 [==============================] - 0s 485us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 490us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 336us/step\n",
      "32/32 [==============================] - 0s 354us/step\n",
      "32/32 [==============================] - 0s 386us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 558us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 494us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 255us/step\n",
      "32/32 [==============================] - 0s 306us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 643us/step\n",
      "32/32 [==============================] - 0s 621us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 746us/step\n",
      "32/32 [==============================] - 0s 340us/step\n",
      "32/32 [==============================] - 0s 374us/step\n",
      "32/32 [==============================] - 0s 412us/step\n",
      "32/32 [==============================] - 0s 578us/step\n",
      "32/32 [==============================] - 0s 544us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 154: early stopping\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 657us/step\n",
      "32/32 [==============================] - 0s 622us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 126us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 304us/step\n",
      "32/32 [==============================] - 0s 868us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 49us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 368us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 323us/step\n",
      "32/32 [==============================] - 0s 338us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 617us/step\n",
      "32/32 [==============================] - 0s 572us/step\n",
      "32/32 [==============================] - 0s 540us/step\n",
      "32/32 [==============================] - 0s 483us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 199us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 708us/step\n",
      "32/32 [==============================] - 0s 687us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 378us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 818us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 667us/step\n",
      "32/32 [==============================] - 0s 487us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 409us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 381us/step\n",
      "32/32 [==============================] - 0s 602us/step\n",
      "32/32 [==============================] - 0s 563us/step\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 126: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 165: early stopping\n",
      "32/32 [==============================] - 0s 732us/step\n",
      "32/32 [==============================] - 0s 715us/step\n",
      "32/32 [==============================] - 0s 681us/step\n",
      "32/32 [==============================] - 0s 447us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 398us/step\n",
      "32/32 [==============================] - 0s 756us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 196us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 720us/step\n",
      "32/32 [==============================] - 0s 696us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "32/32 [==============================] - 0s 78us/step\n",
      "32/32 [==============================] - 0s 288us/step\n",
      "32/32 [==============================] - 0s 326us/step\n",
      "32/32 [==============================] - 0s 163us/step\n",
      "32/32 [==============================] - 0s 622us/step\n",
      "32/32 [==============================] - 0s 589us/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 209us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 716us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 367us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 73us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 846us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 292us/step\n",
      "32/32 [==============================] - 0s 435us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 530us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 166us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 661us/step\n",
      "32/32 [==============================] - 0s 619us/step\n",
      "32/32 [==============================] - 0s 566us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 197: early stopping\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 65us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 686us/step\n",
      "32/32 [==============================] - 0s 645us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 502us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 180us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 751us/step\n",
      "32/32 [==============================] - 0s 714us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 386us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 116us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 750us/step\n",
      "32/32 [==============================] - 0s 740us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 235us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 308us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 633us/step\n",
      "32/32 [==============================] - 0s 580us/step\n",
      "32/32 [==============================] - 0s 408us/step\n",
      "32/32 [==============================] - 0s 976us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 399us/step\n",
      "32/32 [==============================] - 0s 443us/step\n",
      "32/32 [==============================] - 0s 479us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 389us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 339us/step\n",
      "32/32 [==============================] - 0s 345us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 614us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 886us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 425us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 190: early stopping\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 355us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 243us/step\n",
      "32/32 [==============================] - 0s 282us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 685us/step\n",
      "32/32 [==============================] - 0s 653us/step\n",
      "32/32 [==============================] - 0s 612us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 351us/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 430us/step\n",
      "32/32 [==============================] - 0s 570us/step\n",
      "32/32 [==============================] - 0s 546us/step\n",
      "32/32 [==============================] - 0s 495us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 887us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 253us/step\n",
      "32/32 [==============================] - 0s 294us/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 149us/step\n",
      "32/32 [==============================] - 0s 641us/step\n",
      "32/32 [==============================] - 0s 598us/step\n",
      "32/32 [==============================] - 0s 421us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 418us/step\n",
      "32/32 [==============================] - 0s 466us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 501us/step\n",
      "32/32 [==============================] - 0s 801us/step\n",
      "32/32 [==============================] - 0s 271us/step\n",
      "32/32 [==============================] - 0s 745us/step\n",
      "32/32 [==============================] - 0s 697us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 369us/step\n",
      "32/32 [==============================] - 0s 401us/step\n",
      "32/32 [==============================] - 0s 429us/step\n",
      "32/32 [==============================] - 0s 456us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 615us/step\n",
      "32/32 [==============================] - 0s 583us/step\n",
      "32/32 [==============================] - 0s 549us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 875us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 165: early stopping\n",
      "32/32 [==============================] - 0s 823us/step\n",
      "32/32 [==============================] - 0s 797us/step\n",
      "32/32 [==============================] - 0s 756us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 359us/step\n",
      "32/32 [==============================] - 0s 353us/step\n",
      "32/32 [==============================] - 0s 460us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 683us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 608us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 443us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 141us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 603us/step\n",
      "32/32 [==============================] - 0s 257us/step\n",
      "32/32 [==============================] - 0s 728us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 366us/step\n",
      "32/32 [==============================] - 0s 600us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 71us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 850us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 226us/step\n",
      "32/32 [==============================] - 0s 463us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 855us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 902us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 140us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 764us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 238us/step\n",
      "32/32 [==============================] - 0s 261us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 706us/step\n",
      "32/32 [==============================] - 0s 665us/step\n",
      "32/32 [==============================] - 0s 630us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "\n",
      "Epoch 191: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 198: early stopping\n",
      "32/32 [==============================] - 0s 583us/step\n",
      "32/32 [==============================] - 0s 540us/step\n",
      "32/32 [==============================] - 0s 685us/step\n",
      "32/32 [==============================] - 0s 648us/step\n",
      "32/32 [==============================] - 0s 589us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 493us/step\n",
      "32/32 [==============================] - 0s 492us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 723us/step\n",
      "32/32 [==============================] - 0s 658us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 402us/step\n",
      "32/32 [==============================] - 0s 437us/step\n",
      "32/32 [==============================] - 0s 461us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 503us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 349us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 281us/step\n",
      "32/32 [==============================] - 0s 291us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 636us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 438us/step\n",
      "32/32 [==============================] - 0s 191us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 197us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 920us/step\n",
      "32/32 [==============================] - 0s 525us/step\n",
      "32/32 [==============================] - 0s 498us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 300us/step\n",
      "32/32 [==============================] - 0s 666us/step\n",
      "32/32 [==============================] - 0s 612us/step\n",
      "32/32 [==============================] - 0s 436us/step\n",
      "32/32 [==============================] - 0s 471us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 120us/step\n",
      "32/32 [==============================] - 0s 747us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 247us/step\n",
      "32/32 [==============================] - 0s 722us/step\n",
      "32/32 [==============================] - 0s 686us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 177: early stopping\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 702us/step\n",
      "32/32 [==============================] - 0s 631us/step\n",
      "32/32 [==============================] - 0s 606us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 483us/step\n",
      "32/32 [==============================] - 0s 671us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 162us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 749us/step\n",
      "32/32 [==============================] - 0s 728us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 371us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 367us/step\n",
      "32/32 [==============================] - 0s 826us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 286us/step\n",
      "32/32 [==============================] - 0s 387us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 192us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 345us/step\n",
      "32/32 [==============================] - 0s 828us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 86us/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 217us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 725us/step\n",
      "32/32 [==============================] - 0s 689us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 417us/step\n",
      "32/32 [==============================] - 0s 464us/step\n",
      "32/32 [==============================] - 0s 337us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 184: early stopping\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 342us/step\n",
      "32/32 [==============================] - 0s 367us/step\n",
      "32/32 [==============================] - 0s 392us/step\n",
      "32/32 [==============================] - 0s 413us/step\n",
      "32/32 [==============================] - 0s 462us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 808us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 448us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 307us/step\n",
      "32/32 [==============================] - 0s 315us/step\n",
      "32/32 [==============================] - 0s 552us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 256us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 236us/step\n",
      "32/32 [==============================] - 0s 403us/step\n",
      "32/32 [==============================] - 0s 594us/step\n",
      "32/32 [==============================] - 0s 544us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 508us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 869us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 657us/step\n",
      "32/32 [==============================] - 0s 445us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 64us/step\n",
      "32/32 [==============================] - 0s 326us/step\n",
      "32/32 [==============================] - 0s 348us/step\n",
      "32/32 [==============================] - 0s 136us/step\n",
      "32/32 [==============================] - 0s 635us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 543us/step\n",
      "32/32 [==============================] - 0s 500us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 227us/step\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "\n",
      "Epoch 173: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 180: early stopping\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 219us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 702us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 455us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 362us/step\n",
      "32/32 [==============================] - 0s 114us/step\n",
      "32/32 [==============================] - 0s 611us/step\n",
      "32/32 [==============================] - 0s 593us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 484us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 160us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 753us/step\n",
      "32/32 [==============================] - 0s 714us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 760us/step\n",
      "32/32 [==============================] - 0s 424us/step\n",
      "32/32 [==============================] - 0s 292us/step\n",
      "32/32 [==============================] - 0s 302us/step\n",
      "32/32 [==============================] - 0s 176us/step\n",
      "32/32 [==============================] - 0s 638us/step\n",
      "32/32 [==============================] - 0s 590us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 477us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 452us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 298us/step\n",
      "32/32 [==============================] - 0s 770us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 357us/step\n",
      "32/32 [==============================] - 0s 404us/step\n",
      "32/32 [==============================] - 0s 290us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "32/32 [==============================] - 0s 616us/step\n",
      "32/32 [==============================] - 0s 573us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 472us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 81us/step\n",
      "32/32 [==============================] - 0s 554us/step\n",
      "32/32 [==============================] - 0s 524us/step\n",
      "32/32 [==============================] - 0s 489us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 163: early stopping\n",
      "32/32 [==============================] - 0s 533us/step\n",
      "32/32 [==============================] - 0s 278us/step\n",
      "32/32 [==============================] - 0s 736us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 515us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 511us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 468us/step\n",
      "32/32 [==============================] - 0s 609us/step\n",
      "32/32 [==============================] - 0s 580us/step\n",
      "32/32 [==============================] - 0s 526us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 98us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 161us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 517us/step\n",
      "32/32 [==============================] - 0s 905us/step\n",
      "32/32 [==============================] - 0s 506us/step\n",
      "32/32 [==============================] - 0s 513us/step\n",
      "32/32 [==============================] - 0s 505us/step\n",
      "32/32 [==============================] - 0s 249us/step\n",
      "32/32 [==============================] - 0s 523us/step\n",
      "32/32 [==============================] - 0s 514us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 694us/step\n",
      "32/32 [==============================] - 0s 731us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 516us/step\n",
      "32/32 [==============================] - 0s 388us/step\n",
      "32/32 [==============================] - 0s 32us/step\n",
      "32/32 [==============================] - 0s 322us/step\n",
      "32/32 [==============================] - 0s 331us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 619us/step\n",
      "32/32 [==============================] - 0s 596us/step\n",
      "32/32 [==============================] - 0s 555us/step\n",
      "32/32 [==============================] - 0s 497us/step\n",
      "32/32 [==============================] - 0s 949us/step\n",
      "32/32 [==============================] - 0s 0s/step\n",
      "32/32 [==============================] - 0s 481us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 520us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 509us/step\n",
      "32/32 [==============================] - 0s 507us/step\n",
      "32/32 [==============================] - 0s 510us/step\n",
      "32/32 [==============================] - 0s 518us/step\n",
      "32/32 [==============================] - 0s 707us/step\n",
      "32/32 [==============================] - 0s 653us/step\n",
      "32/32 [==============================] - 0s 637us/step\n",
      "32/32 [==============================] - 0s 512us/step\n",
      "32/32 [==============================] - 0s 416us/step\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "###########################\n",
    "####### AUTOENCODER #######\n",
    "###########################\n",
    "df = pd.read_csv('../data/CO2_clean.csv', usecols=['Index', 'T', 'P', 'D'])\n",
    "X = df[['T', 'P', 'D']]\n",
    "y = df['D']\n",
    "## Set callbacks ##\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "reduce_lron_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "##  Define the Architecture ##\n",
    "input_layer = keras.Input(shape=(3,), name='input_layer')\n",
    "encoder_layer_1 = layers.Dense(44, activation='elu', name='encoder_layer_1')(input_layer)\n",
    "encoder_layer_2 = layers.Dense(72, activation='elu', name='encoder_layer_2')(encoder_layer_1)\n",
    "latent = layers.Dense(2, activation='elu', name='latent_space')(encoder_layer_2)\n",
    "decoder_layer_1 = layers.Dense(72, activation='elu', name='decoder_layer_1')(latent)\n",
    "decoder_layer_2 = layers.Dense(44, activation='elu', name='decoder_layer_2')(decoder_layer_1)\n",
    "output_layer = layers.Dense(3, activation='elu', name='output_layer')(decoder_layer_2)\n",
    "\n",
    "scaler_full = MinMaxScaler()\n",
    "X_scaled = scaler_full.fit_transform(X)\n",
    "autoencoder_full = keras.Model(input_layer, output_layer)\n",
    "autoencoder_full.compile(optimizer='adam', loss='mse')\n",
    "history_full = autoencoder_full.fit(X_scaled, X_scaled,\n",
    "                               verbose=0,\n",
    "                               epochs=1000,\n",
    "                               batch_size=32,\n",
    "                               shuffle=False,\n",
    "                               validation_data=(X_scaled, X_scaled),\n",
    "                               callbacks=[reduce_lron_plateau, early_stopping])\n",
    "\n",
    "df_auto_results_full = export_results_autoencoder(autoencoder_full, scaler_full)\n",
    "plot_sensitivity(df_auto_results_full,'Autoencoder',save_params)"
   ],
   "id": "376f0f29f9e1c601",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
